{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPI_Tu--g0hc",
        "outputId": "ee2c04b7-55fe-4368-95eb-e372d15d478e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-11 23:11:34--  https://zenodo.org/record/3532678/files/data.tar.gz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10918523087 (10G) [application/octet-stream]\n",
            "Saving to: ‘data.tar.gz’\n",
            "\n",
            "data.tar.gz           0%[                    ]   7.54M   249KB/s    eta 11h 49m"
          ]
        }
      ],
      "source": [
        "!wget -O data.tar.gz https://zenodo.org/record/3532678/files/data.tar.gz?download=1\n",
        "!tar -xzf /content/data.tar.gz >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zX8gnRC7Wv8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import glob\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import random\n",
        "\n",
        "torch.manual_seed(12515)\n",
        "from tqdm import tqdm\n",
        "from time import time, ctime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PaBWVgK8VNP"
      },
      "outputs": [],
      "source": [
        "!mkdir data2export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D0UjptcAw4y"
      },
      "outputs": [],
      "source": [
        "!rm /content/data2export/trainset.csv\n",
        "!rm /content/data2export/valset.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO9QqQcBKbpd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEhZEOOY_H2z"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/data2export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY0hzIdS_lW6"
      },
      "outputs": [],
      "source": [
        "!mkdir data2export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GryBGCbXjT1C"
      },
      "outputs": [],
      "source": [
        "train_file = open('/content/data2export/trainset.csv', 'a')\n",
        "val_file = open('/content/data2export/valset.csv', 'a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEmRWLLJ6BCg"
      },
      "outputs": [],
      "source": [
        "print('Importing data...')\n",
        "data_files = glob.glob('/content/data/dm_math' + '/*/train.xy')\n",
        "data_files.remove('/content/data/dm_math/all_modules/train.xy')\n",
        "for data_file in tqdm(data_files):\n",
        "\n",
        "  with open(data_file ,'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for a in lines[200_000:380_000]:\n",
        "      train_file.write(a)\n",
        "    for b in lines[380_000:400_000]:\n",
        "      val_file.write(b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRORn2k89RZz"
      },
      "outputs": [],
      "source": [
        "train_size = os.path.getsize('/content/data2export/trainset.csv')\n",
        "val_size = os.path.getsize('/content/data2export/valset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bjFUQ2qCR1E"
      },
      "outputs": [],
      "source": [
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:.1f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.1f} Yi{suffix}\"\n",
        "\n",
        "file_size_readable_train = sizeof_fmt(train_size, 'Gi')\n",
        "file_size_readable_val = sizeof_fmt(val_size, 'Gi')\n",
        "\n",
        "print('Memoria occupata dal train file: ', file_size_readable_train)\n",
        "print('Memoria occupata dal val file: ', file_size_readable_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmwVe2y5LMdD"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/data2export/interpolate\n",
        "!mkdir /content/data2export/extrapolate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWE8UVlwMvZa"
      },
      "outputs": [],
      "source": [
        "# Use glob to get a list of paths that match the pattern\n",
        "data_files = glob.glob('/content/data/dm_math' + '/*/interpolate.xy')\n",
        "data_files.remove('/content/data/dm_math/all_modules/interpolate.xy')\n",
        "tasks_interpolate = []\n",
        "for data_file in data_files:\n",
        "  task_name = data_file.split('/')[-2]\n",
        "  tasks_interpolate.append(task_name)\n",
        "\n",
        "  task_file = open('/content/data2export/interpolate/' + task_name +'.csv', 'a')\n",
        "  with open(data_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for a in lines:\n",
        "      task_file.write(a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIEgsSsR1GFr"
      },
      "outputs": [],
      "source": [
        "print(tasks_interpolate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d9nggjoQEkT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Use glob to get a list of paths that match the pattern\n",
        "data_files = glob.glob('/content/data/dm_math' + '/*/extrapolate.xy')\n",
        "data_files.remove('/content/data/dm_math/all_modules/extrapolate.xy')\n",
        "tasks_extrapolate = []\n",
        "for data_file in data_files:\n",
        "  task_name = data_file.split('/')[-2]\n",
        "\n",
        "  tasks_extrapolate.append(task_name)\n",
        "\n",
        "  task_file = open('/content/data2export/extrapolate/' + task_name +'.csv', 'a')\n",
        "\n",
        "  with open(data_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for a in lines:\n",
        "      task_file.write(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrEPtF7s1Ys8"
      },
      "outputs": [],
      "source": [
        "print(tasks_extrapolate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxcTYWXSQeMr"
      },
      "outputs": [],
      "source": [
        "!tar -czvf math_data_200k.tar.gz /content/data2export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G-fL1lsn6Mb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7eBjxyl68Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8E-6-HHmqYk"
      },
      "outputs": [],
      "source": [
        "!cp /content/math_data_200k.tar.gz /content/drive/MyDrive/DeepLproject_2023/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qkS_OLyp8tQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kspck7hcsS9U"
      },
      "outputs": [],
      "source": [
        "from pickle import NONE\n",
        "class MathData(Dataset):\n",
        "  def __init__(self, dir_path, partition, task=None, max_len = 200):\n",
        "    self.dir_path = dir_path\n",
        "\n",
        "    self.data = []\n",
        "    self.max_len = max_len\n",
        "    self.pad_char =  '˽'\n",
        "    self.prefix_char = '$'\n",
        "    self.suffix_char = '§'\n",
        "    self.digit2idx = {'˽': 0, '$': 1, '§': 2, 'w': 3, 'h': 4, 'a': 5, 't': 6, ' ': 7, 'i': 8, 's': 9, 'p': 10, 'r': 11, 'o': 12, 'b': 13, 'f': 14, 'e': 15, 'q': 16, 'u': 17, 'n': 18, 'c': 19, 'l': 20, 'k': 21, 'd': 22, 'm': 23, '?': 24, '0': 25, '{': 26, 'g': 27, ':': 28, '3': 29, ',': 30, '1': 31, '7': 32, '}': 33, '.': 34, 'v': 35, '/': 36, '4': 37, 'x': 38, '5': 39, '2': 40, '9': 41, '8': 42, 'z': 43, 'y': 44, '6': 45, 'j': 46, '-': 47, '*': 48, '+': 49, '=': 50, '(': 51, ')': 52, \"'\": 53, '>': 54, '<': 55, '!': 56}\n",
        "    self.idx2digit = {v : k for k,v in self.digit2idx.items()}\n",
        "    self.tasks_interpolate = ['probability__swr_p_sequence', 'probability__swr_p_level_set', 'numbers__lcm_composed', 'calculus__differentiate_composed', 'numbers__lcm', 'algebra__linear_1d', 'arithmetic__add_sub_multiple', 'polynomials__simplify_power', 'measurement__conversion', 'polynomials__compose', 'numbers__base_conversion', 'polynomials__evaluate', 'arithmetic__mul', 'algebra__linear_1d_composed', 'arithmetic__add_or_sub', 'numbers__place_value_composed', 'polynomials__add', 'numbers__list_prime_factors_composed', 'arithmetic__mul_div_multiple', 'measurement__time', 'numbers__div_remainder', 'arithmetic__simplify_surd', 'numbers__place_value', 'comparison__closest_composed', 'polynomials__expand', 'numbers__is_factor', 'numbers__div_remainder_composed', 'arithmetic__nearest_integer_root', 'numbers__round_number_composed', 'arithmetic__mixed', 'algebra__polynomial_roots_composed', 'algebra__sequence_nth_term', 'arithmetic__add_or_sub_in_base', 'comparison__pair_composed', 'algebra__linear_2d', 'polynomials__coefficient_named', 'comparison__kth_biggest', 'comparison__sort', 'polynomials__collect', 'numbers__list_prime_factors', 'algebra__polynomial_roots', 'numbers__round_number', 'numbers__is_prime', 'algebra__sequence_next_term', 'comparison__closest', 'comparison__sort_composed', 'numbers__gcd', 'arithmetic__div', 'numbers__gcd_composed', 'calculus__differentiate', 'numbers__is_prime_composed', 'comparison__pair', 'numbers__is_factor_composed', 'polynomials__evaluate_composed', 'algebra__linear_2d_composed', 'comparison__kth_biggest_composed']\n",
        "    self.tasks_extrapolate = ['probability__swr_p_level_set_more_samples', 'measurement__conversion', 'arithmetic__mixed_longer', 'arithmetic__mul_big', 'arithmetic__mul_div_multiple_longer', 'comparison__sort_more', 'arithmetic__add_or_sub_big', 'comparison__closest_more', 'comparison__kth_biggest_more', 'arithmetic__div_big', 'arithmetic__add_sub_multiple_longer', 'numbers__round_number_big', 'probability__swr_p_sequence_more_samples', 'numbers__place_value_big', 'algebra__polynomial_roots_big']\n",
        "\n",
        "    print('Loarding', partition, 'data...')\n",
        "    self.load_data(dir_path, partition, task)\n",
        "\n",
        "  def load_data(self, dir_path, partition, task = None): #partition choose between ('train', 'val')\n",
        "    if partition == 'train':\n",
        "      data_path = os.path.join(dir_path, 'trainset.csv')\n",
        "\n",
        "    elif partition == 'val':\n",
        "      data_path = os.path.join(dir_path, 'valset.csv')\n",
        "\n",
        "    elif partition == 'interpolate':\n",
        "      if isinstance(task, (int)):\n",
        "        data_path = os.path.join(dir_path, 'interpolate', self.tasks_interpolate[task] + '.csv')\n",
        "      else:\n",
        "        data_path = os.path.join(dir_path, 'interpolate', task + '.csv')\n",
        "\n",
        "    elif partition =='extrapolate':\n",
        "      if isinstance(task, (int)):\n",
        "        data_path = os.path.join(dir_path, 'extrapolate', self.tasks_extrapolate[task] +'.csv')\n",
        "      else:\n",
        "        data_path = os.path.join(dir_path, 'extrapolate', task + '.csv')\n",
        "\n",
        "    else:\n",
        "      raise Exception('Please choose the partition between [train, val, interpolate, extrapolate]')\n",
        "\n",
        "    with open(data_path, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "      for line in tqdm(lines):\n",
        "        self.data.append(line)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    line = self.data[idx].split('\\t')\n",
        "\n",
        "    x_digits = [self.digit2idx[self.prefix_char]] + [self.digit2idx[digit.lower()] for digit in line[0]] + [self.digit2idx[self.suffix_char]] + [self.digit2idx[self.pad_char]]*(self.max_len-3-len(line[0]))\n",
        "\n",
        "    y_digits = [self.digit2idx[self.prefix_char]] + [self.digit2idx[digit.lower()] for digit in line[1].replace('\\n', '')] + [self.digit2idx[self.suffix_char]] + [self.digit2idx[self.pad_char]]*(self.max_len-3-len(line[1].replace('\\n', '')))\n",
        "\n",
        "    x_ids = torch.LongTensor(x_digits)\n",
        "    y_ids = torch.LongTensor(y_digits)\n",
        "    return x_ids, y_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMpbGUeIudv0"
      },
      "outputs": [],
      "source": [
        "wow = MathData('/content/data2export', 'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mZNmwaWvFeg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl5-3Zem0p-u"
      },
      "outputs": [],
      "source": [
        "bebe = MathData('/content/data2export', 'interpolate', 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJcz7O1Z3Rbi"
      },
      "outputs": [],
      "source": [
        "bebe[533]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjNtugEt3wfF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
